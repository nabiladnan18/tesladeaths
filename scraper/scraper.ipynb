{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE\n",
    "SOURCE = \"https://www.tesladeaths.com\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession, Element\n",
    "\n",
    "session = HTMLSession()\n",
    "r: session = session.get(SOURCE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the `table` element that houses the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table: Element = r.html.find(\"#dttable\", first=True)\n",
    "table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding all row headers using `th` tag.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_headers = table.find(\"th\")[:12]\n",
    "table_headers = [row.text for row in table_headers]\n",
    "table_headers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting all data rows and excluding the last 350 since there is no usable data in there.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data = table.find(\"tr\")[1:]\n",
    "# The first tr has all the headings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [row.text.split(\"\\n\")[:12] for row in table_data]\n",
    "for row in rows:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were some challenges arranging the data in the right way.\n",
    "\n",
    "-  ~~The urls in the table are truncated, which means simply finding the text would not suffice.~~ Changed approach to `tr` instead of `td`. Extracted the first 12 columns which is what we really need.\n",
    "\n",
    "~~-   There are more than **one** URL per row. There are numbers in the table are _hyperlinked_ which means there are more URLs than are rows, which makes it difficult to simply find all the `a` tags and plug them into the table at the right index while looping through all the elements in `table_data`. Speaking of which...~~\n",
    "\n",
    "~~-   The collection of elements in `table_data` is simply a dump of the table; not by row. There are 23 columns in the table therefore, for each 23 elements found from the beginning is one row.~~\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mandatory conversion to DataFrame üòÖ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(rows, columns=table_headers)\n",
    "# Converting necessary columns from str to int values\n",
    "int_value_columns = df.columns[6:12]\n",
    "df[int_value_columns] = (\n",
    "    df[int_value_columns].apply(pd.to_numeric, errors=\"coerce\").fillna(0).astype(\"int\")\n",
    ")\n",
    "\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_point = df[df[\"Case #\"] == \"1\"].index.values[0] + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:cutoff_point]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Played around with the new library `Polars` üêª‚Äç‚ùÑÔ∏è which is supposed to be [`faaaast`](https://www.youtube.com/shorts/6E7ZGCfruaw). It is indeed, or should be in theory. `Polars` store data in DataFrames in _columnar_ format as opposed to the classical row format _Pandas_ üêº uses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import polars as pl\n",
    "\n",
    "# pl_rows = pl.DataFrame(rows)\n",
    "# pl_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting from `mm/dd/yyyy` to `dd/mm/yyyy`. It is possible to convert them into `datetime` objects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s %(levelname)s: %(message)s\", level=logging.INFO)\n",
    "\n",
    "\n",
    "def convert_datestring(date_string):\n",
    "    try:\n",
    "        date_object = datetime.strptime(date_string, \"%m/%d/%Y\")\n",
    "        return date_object.strftime(\"%Y-%m-%d\")\n",
    "    except ValueError as e:\n",
    "        logging.warning(f\"Could not convert {date_string} into datetime object: {e}\")\n",
    "        logging.info(\"Assigning a random date.\")\n",
    "        date_parts = date_string.split(\"/\")\n",
    "        for index, date_part in enumerate(date_parts):\n",
    "            try:\n",
    "                int(date_part)\n",
    "            except ValueError:\n",
    "                date_parts[index] = \"12\"\n",
    "                return convert_datestring(\"/\".join(date_parts))\n",
    "\n",
    "\n",
    "df[\"Date\"] = df[\"Date\"].apply(convert_datestring)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's convert the dates into a datetime object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df[\"Date\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Holland` and `Netherlands` appear in the list of countries, although they are the same! Replacing the former with the latter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Country\"].replace({\"Holland\": \"Netherlands\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally! Write the data out to a `.csv` file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data.csv\", index=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dtypes` change when reading from `csv`, as it tries to infer the data type for each column. For example, the year converts to `int64`. It is possible to change the `dtype` into something else by passing the `dtype` argument in `read_csv` using a `key-value` of a column name and desired `dtype`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data.csv\")\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data.csv\", dtype={\"Case #\": str, \"Year\": str, \"Date\": str})\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last updated on\n",
    "import re\n",
    "\n",
    "pattern = re.compile(\"\\d{4}-\\d{2}-\\d{2}\")\n",
    "html = r.html.find(\"em\")\n",
    "\n",
    "last_updated_on = []\n",
    "for em in html:\n",
    "    match = pattern.search(em.text)\n",
    "    if match:\n",
    "        last_updated_on.append(match.group())\n",
    "\n",
    "last_updated_on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesla_deaths-wxKVL54F",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
